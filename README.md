# Robust face recognition in a video

The Python script, *face-rec.py*, performs face recognition in a video using FaceNet and MTCNN. It compares all detected faces in the video with a reference face image and marks identified faces in the output video.

The entire video is processed frame by frame. Detected faces are compared with the reference face by analyzing their embeddings using cosine similarity. The MTCNN model detects faces in the video, while the FaceNet (InceptionResnetV1) model generates face embeddings.

The output video contains bounding boxes and labels ("Identified" / "Not identified"). The code is robust against low-quality frames, frames without faces, and head turns.

## Tests
I performed some tests to demonstrate practical issues.

Fig. 1 shows the output video generated with *face-rec.py* using a similarity threshold of 0.6. We observe some false positive identifications, where two people are mistakenly recognized as the reference face, whereas we expect to recognize only the man on the left. This issue may be related to the AI-generated nature of the video, as AI-generated faces can sometimes share similar features.

![Output video](output_video_0.6.gif "Output video")

Fig. 1. Output video generated with *face-rec.py*, similarity=0.6

In this case, increasing the similarity threshold—for example, to 0.7—makes sense. Fig. 2 shows the output video generated with *face-rec.py* using this updated threshold.

![Output video](output_video_0.7.gif "Output video")

Fig. 2. Output video generated with *face-rec.py*, similarity=0.7

From Fig. 2, we see that false positive identifications are eliminated. However, sometimes the man on the left is not recognized, likely because the similarity threshold is too high. To improve recognition, we can fine-tune the similarity threshold within the 0.6–0.7 range to find an optimal value.

### Alternative Approach: Using Multiple Reference Faces

Instead of adjusting the similarity threshold alone, we can use multiple reference faces. For example, we can select a full-face view and one or more profile views. By computing an average embedding from these images, we obtain a more comprehensive representation of the reference face, improving recognition accuracy.

The script *face-rec_avg.py* implements this approach.

Fig. 3 shows the output video generated with *face-rec_avg.py* using a similarity threshold of 0.7. The recognition results are more reliable in this case.

![Output video](output_video_0.7_avg.gif "Output video")

Fig. 3. Output video generated with *face-rec_avg.py*, similarity=0.7

---

Required libraries are listed in requirements.txt. Note that you may need to install a proper version of PyTorch + CUDA as well as the CUDA Toolkit to use GPUs. 

**All faces in the videos and the reference face image are synthetically generated by AI and do not represent real people. The content was created using [Kling AI](https://klingai.com/) and is used solely for demonstration purposes.**
